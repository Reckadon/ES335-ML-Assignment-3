{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pprint import pprint\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'warpeace.txt'\n",
    "# Load the text\n",
    "with open(filepath, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546565\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "text = text.lower()  # Convert to lowercase\n",
    "text = re.sub(r'[^a-z\\s\\.]', '', text)  # Remove special characters except full stops\n",
    "words = text.split()  # Split into words\n",
    "words = [word for word in words if word]  # Remove empty strings\n",
    "\n",
    "# Remove words with less than 2 characters (for this example)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "print(len(words))\n",
    "words = pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546560\n",
      "546560\n"
     ]
    }
   ],
   "source": [
    "unique_words = sorted(set(words))\n",
    "stoi = {s: i + 1 for i, s in enumerate(unique_words)}  # Map words to indices\n",
    "stoi['.'] = 0  # End-of-sentence token\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "\n",
    "# Prepare input-output pairs\n",
    "block_size = 5  # Number of words to use as context\n",
    "X, Y = [], []\n",
    "\n",
    "for i in range(len(words) - block_size):\n",
    "    context = [0] * block_size  # Start with the end-of-sentence token\n",
    "    for j in range(block_size):\n",
    "        context[j] = stoi[words[i + j]]\n",
    "    X.append(context)\n",
    "    Y.append(stoi[words[i + block_size]])# The next word to predict\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.long)  # Input tensor\n",
    "Y = torch.tensor(Y, dtype=torch.long)  # Output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "emb_dim = 64  # Larger embedding size for words\n",
    "hidden_size = 1024  # Larger hidden layer size\n",
    "\n",
    "class NextWord(nn.Module):\n",
    "    def __init__(self, block_size, vocab_size, emb_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lin1 = nn.Linear(block_size * emb_dim, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the embeddings\n",
    "        x = F.tanh(self.lin1(x))  # Use tanh activation\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = NextWord(block_size, len(stoi), emb_dim, hidden_size).to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word(model, itos, stoi, block_size, max_len=10):\n",
    "    context = [0] * block_size  # Start with end-of-sentence token\n",
    "    words_generated = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor(context).view(1, -1).to(device)\n",
    "        y_pred = model(x)\n",
    "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
    "        word = itos[ix]\n",
    "        if word == '.':\n",
    "            break\n",
    "        words_generated.append(word)\n",
    "        context = context[1:] + [ix]  # Update context\n",
    "\n",
    "    return ' '.join(words_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted next word for the input 'The men fought very bravely' is: 'from'\n"
     ]
    }
   ],
   "source": [
    "block_size = 5\n",
    "try:\n",
    "    mcopy = torch.load('model-Emb64-Con5-Tanh.pth')\n",
    "except:\n",
    "    mcopy = torch.load('model-Emb64-Con5-Tanh.pth',map_location=device)\n",
    "mcopy.eval()\n",
    "# Function to preprocess the input sentence\n",
    "def preprocess_input(sentence, stoi, block_size):\n",
    "    sentence = sentence.lower()  # Convert to lowercase\n",
    "    sentence = re.sub(r'[^a-z\\s\\.]', '', sentence)  # Remove special characters except full stops\n",
    "    words = sentence.split()  # Split into words\n",
    "    words = [word for word in words if word]  # Remove empty strings\n",
    "\n",
    "    # Create context from the last block_size words\n",
    "    context = [0] * block_size  # Start with the end-of-sentence token\n",
    "    for i in range(block_size):\n",
    "        if i < len(words):\n",
    "            word = words[i]\n",
    "            context[i] = stoi.get(word, 0)  # Get the index, use 0 if word not in vocab\n",
    "        else:\n",
    "            context[i] = 0  # Fill with end-of-sentence token if fewer words\n",
    "\n",
    "    return context\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"The men fought very bravely\"\n",
    "\n",
    "# Preprocess the input sentence\n",
    "context = preprocess_input(input_sentence, stoi, block_size)\n",
    "\n",
    "# Convert context to tensor and send to device\n",
    "context_tensor = torch.tensor(context, dtype=torch.long).view(1, -1).to(device)\n",
    "\n",
    "# Generate the next word\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    y_pred = mcopy(context_tensor)  # Forward pass\n",
    "    ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()  # Sample from the distribution\n",
    "    next_word = itos[ix]  # Convert index to word\n",
    "\n",
    "print(f\"The predicted next word for the input '{input_sentence}' is: '{next_word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, context, itos, stoi, block_size, max_len=10):\n",
    "    context = preprocess_input(context, stoi, block_size)\n",
    "    words_generated = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor(context).view(1, -1).to(device)\n",
    "        y_pred = model(x)\n",
    "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
    "        word = itos[ix]\n",
    "        if word == '.':\n",
    "            break\n",
    "        words_generated.append(word)\n",
    "        context = context[1:] + [ix]  # Update context\n",
    "\n",
    "    return ' '.join(words_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_app.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Streamlit App\n",
    "st.title('Next Word Prediction')\n",
    "st.write('This app predicts the next word in a sentence using a simple neural network model trained on the text of War and Peace.')\n",
    "\n",
    "# Input fields\n",
    "input_sentence = st.text_input('Enter initial text for prediction:', placeholder=\"e.g., 'It was a bright cold day in April'\")\n",
    "contextLength = st.selectbox(\"Context Length\", [5, 10])\n",
    "embeddingDim = st.selectbox(\"Embedding Dimension\", [64, 128])\n",
    "activation = st.selectbox(\"Activation Function\", ['tanh', 'ReLU'])\n",
    "maxLen = st.number_input('Max Length of Prediction', 1, 20, 1)\n",
    "randomSeed = st.number_input('Random Seed', value=42)\n",
    "\n",
    "# Prediction Button\n",
    "if st.button('Predict Next Word/Letter'):\n",
    "    try:\n",
    "        # Placeholder for demonstration; replace with actual model prediction\n",
    "        ans = \"Example prediction text\"  \n",
    "        st.write(f\"Generated Text: {ans}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run streamlit_app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
